{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy, pandas and pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDataSets(df_list, X_cut = 1):\n",
    "    \"\"\"\n",
    "        This function merges the data frames in df_list in one data_frame.\n",
    "        The entries of the final data_frame will be ordered by \"X\"\n",
    "        X_cut will remove data with X > X_cut from the merged data_set\n",
    "    \"\"\"\n",
    "    data = pd.concat(df_list, ignore_index=True, sort = False)\n",
    "    for column in data.columns:\n",
    "        data[column] = np.array(data[column], np.float64)\n",
    "    data = data[data[\"X\"] < X_cut]\n",
    "    data = data.sort_values(by=[\"X\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TPC data\n",
    "# Table1.csv data\n",
    "cols_list = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2\", \"error +\", \"error -\"]\n",
    "TPC_dataset1_table1 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table1.csv\", skiprows = 12)\n",
    "TPC_dataset1_table1[\"Q**2 [GEV**2]\"] = 0.24\n",
    "TPC_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 0.2\n",
    "TPC_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 0.3\n",
    "TPC_dataset1_table1 = TPC_dataset1_table1[cols_list]\n",
    "# Table2.csv data\n",
    "TPC_dataset1_table2 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table2.csv\", skiprows = 12)\n",
    "TPC_dataset1_table2[\"Q**2 [GEV**2]\"] = 0.38\n",
    "TPC_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 0.3\n",
    "TPC_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 0.5\n",
    "TPC_dataset1_table2 = TPC_dataset1_table2[cols_list]\n",
    "# Table3.csv data\n",
    "TPC_dataset1_table3 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table3.csv\", skiprows = 12)\n",
    "TPC_dataset1_table3[\"Q**2 [GEV**2]\"] = 0.71\n",
    "TPC_dataset1_table3[\"Q**2 [GEV**2] LOW\"] = 0.5\n",
    "TPC_dataset1_table3[\"Q**2 [GEV**2] HIGH\"] = 1.0\n",
    "TPC_dataset1_table3 = TPC_dataset1_table3[cols_list]\n",
    "# Table4.csv data\n",
    "TPC_dataset1_table4 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table4.csv\", skiprows = 12)\n",
    "TPC_dataset1_table4[\"Q**2 [GEV**2]\"] = 1.3\n",
    "TPC_dataset1_table4[\"Q**2 [GEV**2] LOW\"] = 1.0\n",
    "TPC_dataset1_table4[\"Q**2 [GEV**2] HIGH\"] = 1.6\n",
    "TPC_dataset1_table4 = TPC_dataset1_table4[cols_list]\n",
    "# Table5.csv data\n",
    "TPC_dataset1_table5 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table5.csv\", skiprows = 12)\n",
    "TPC_dataset1_table5[\"Q**2 [GEV**2]\"] = 2.8\n",
    "TPC_dataset1_table5[\"Q**2 [GEV**2] LOW\"] = 1.8\n",
    "TPC_dataset1_table5[\"Q**2 [GEV**2] HIGH\"] = 4.0\n",
    "TPC_dataset1_table5 = TPC_dataset1_table5[cols_list]\n",
    "# Table6.csv data\n",
    "TPC_dataset1_table6 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table6.csv\", skiprows = 12)\n",
    "TPC_dataset1_table6[\"Q**2 [GEV**2]\"] = 5.1\n",
    "TPC_dataset1_table6[\"Q**2 [GEV**2] LOW\"] = 4.0\n",
    "TPC_dataset1_table6[\"Q**2 [GEV**2] HIGH\"] = 6.6\n",
    "TPC_dataset1_table6 = TPC_dataset1_table6[cols_list]\n",
    "# Table7.csv data\n",
    "TPC_dataset1_table7 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table7.csv\", skiprows = 12)\n",
    "TPC_dataset1_table7[\"X\"] = 0.05\n",
    "TPC_dataset1_table7[\"X LOW\"] = 0.0\n",
    "TPC_dataset1_table7[\"X HIGH\"] = 0.1\n",
    "TPC_dataset1_table7 = TPC_dataset1_table7[cols_list]\n",
    "# Table8.csv data\n",
    "TPC_dataset1_table8 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table8.csv\", skiprows = 12)\n",
    "TPC_dataset1_table8[\"X\"] = 0.15\n",
    "TPC_dataset1_table8[\"X LOW\"] = 0.1\n",
    "TPC_dataset1_table8[\"X HIGH\"] = 0.2\n",
    "TPC_dataset1_table8 = TPC_dataset1_table8[cols_list]\n",
    "# Table9.csv data\n",
    "TPC_dataset1_table9 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table9.csv\", skiprows = 12)\n",
    "TPC_dataset1_table9[\"X\"] = 0.25\n",
    "TPC_dataset1_table9[\"X LOW\"] = 0.2\n",
    "TPC_dataset1_table9[\"X HIGH\"] = 0.3\n",
    "TPC_dataset1_table9 = TPC_dataset1_table9[cols_list]\n",
    "# Table10.csv data\n",
    "TPC_dataset1_table10 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table10.csv\", skiprows = 12)\n",
    "TPC_dataset1_table10[\"X\"] = 0.45\n",
    "TPC_dataset1_table10[\"X LOW\"] = 0.3\n",
    "TPC_dataset1_table10[\"X HIGH\"] = 0.6\n",
    "TPC_dataset1_table10 = TPC_dataset1_table10[cols_list]\n",
    "# Table11.csv data\n",
    "TPC_dataset1_table11 = pd.read_csv(\"TPC_collaboration_data/dataset1/Table11.csv\", skiprows = 12)\n",
    "TPC_dataset1_table11[\"Q**2 [GEV**2]\"] = 0.7\n",
    "TPC_dataset1_table11[\"Q**2 [GEV**2] LOW\"] = 0.3\n",
    "TPC_dataset1_table11[\"Q**2 [GEV**2] HIGH\"] = 1.6\n",
    "TPC_dataset1_table11 = TPC_dataset1_table11[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DELPHI data\n",
    "cols_list = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2/ALPHA\", \"stat +\", \"stat -\", \"sys +\", \"sys -\"]\n",
    "# Table1.csv data\n",
    "DELPHI_dataset1_table1 = pd.read_csv(\"DELPHI_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "DELPHI_dataset1_table1[\"Q**2 [GEV**2]\"] = 12.0\n",
    "DELPHI_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 4.0\n",
    "DELPHI_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 30.0\n",
    "DELPHI_dataset1_table1 = DELPHI_dataset1_table1[cols_list]\n",
    "# Table2.csv data\n",
    "DELPHI_dataset1_table2 = pd.read_csv(\"DELPHI_collaboration_data/dataset1/Table2.csv\", skiprows = 12)\n",
    "DELPHI_dataset1_table2[\"Q**2 [GEV**2]\"] = 12.0\n",
    "DELPHI_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 4.0\n",
    "DELPHI_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 30.0\n",
    "DELPHI_dataset1_table2 = DELPHI_dataset1_table2[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALEPH data\n",
    "cols_list = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2/ALPHAE\", \"stat +\", \"stat -\", \"sys +\", \"sys -\"]\n",
    "# Table4.csv data\n",
    "ALEPH_dataset1_table4 = pd.read_csv(\"ALEPH_collaboration_data/dataset1/Table4.csv\", skiprows = 12)\n",
    "ALEPH_dataset1_table4[\"Q**2 [GEV**2]\"] = 284.0\n",
    "ALEPH_dataset1_table4[\"Q**2 [GEV**2] LOW\"] = (284.0-49)\n",
    "ALEPH_dataset1_table4[\"Q**2 [GEV**2] HIGH\"] = (284.0+49.0)\n",
    "ALEPH_dataset1_table4 = ALEPH_dataset1_table4[cols_list]\n",
    "# Table6.csv data\n",
    "ALEPH_dataset1_table6 = pd.read_csv(\"ALEPH_collaboration_data/dataset1/Table6.csv\", skiprows = 12)\n",
    "ALEPH_dataset1_table6[\"Q**2 [GEV**2]\"] = 20.67\n",
    "ALEPH_dataset1_table6[\"Q**2 [GEV**2] LOW\"] = (20.67-0.16)\n",
    "ALEPH_dataset1_table6[\"Q**2 [GEV**2] HIGH\"] = (20.67+0.16)\n",
    "ALEPH_dataset1_table6 = ALEPH_dataset1_table6[cols_list]\n",
    "# Table8.csv data\n",
    "ALEPH_dataset1_table8 = pd.read_csv(\"ALEPH_collaboration_data/dataset1/Table8.csv\", skiprows = 12)\n",
    "ALEPH_dataset1_table8[\"Q**2 [GEV**2]\"] = 9.93\n",
    "ALEPH_dataset1_table8[\"Q**2 [GEV**2] LOW\"] = (9.93-0.04)\n",
    "ALEPH_dataset1_table8[\"Q**2 [GEV**2] HIGH\"] = (9.93+0.04)\n",
    "ALEPH_dataset1_table8 = ALEPH_dataset1_table8[cols_list]\n",
    "# Table1.csv data\n",
    "cols_list = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2(C=GAMMA)/ALPHAE\", \"stat +\", \"stat -\", \"sys +\", \"sys -\"]\n",
    "ALEPH_dataset2_table1 = pd.read_csv(\"ALEPH_collaboration_data/dataset2/Table1.csv\", skiprows = 12)\n",
    "ALEPH_dataset2_table1[\"Q**2 [GEV**2]\"] = 17.3\n",
    "ALEPH_dataset2_table1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "ALEPH_dataset2_table1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "ALEPH_dataset2_table1 = ALEPH_dataset2_table1[cols_list]\n",
    "# Table2.csv data\n",
    "ALEPH_dataset2_table2 = pd.read_csv(\"ALEPH_collaboration_data/dataset2/Table2.csv\", skiprows = 12)\n",
    "ALEPH_dataset2_table2[\"Q**2 [GEV**2]\"] = 67.2\n",
    "ALEPH_dataset2_table2[\"Q**2 [GEV**2] LOW\"] = 30.0\n",
    "ALEPH_dataset2_table2[\"Q**2 [GEV**2] HIGH\"] = 250.0\n",
    "ALEPH_dataset2_table2 = ALEPH_dataset2_table2[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load L3 data\n",
    "# Dataset1\n",
    "# Load Table1.csv\n",
    "cols_list_set1 = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2(C=SET1)/ALPHA\", \"stat +\", \"stat -\", \"sys +\", \"sys -\"]\n",
    "cols_list_set2 = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2(C=SET2)/ALPHA\", \"stat +\", \"stat -\", \"sys +\", \"sys -\"]\n",
    "L3_dataset1_table1_raw = pd.read_csv(\"L3_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "L3_dataset1_table1_set1 = L3_dataset1_table1_raw[:][:6]\n",
    "L3_dataset1_table1_set2 = L3_dataset1_table1_raw[:][10:]\n",
    "L3_dataset1_table1_set2.columns = ['X', 'X LOW', 'X HIGH', 'F2(C=SET2)/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']\n",
    "L3_dataset1_table1_set1[\"Q**2 [GEV**2]\"] = 1.9\n",
    "L3_dataset1_table1_set1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table1_set1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table1_set2[\"Q**2 [GEV**2]\"] = 1.9\n",
    "L3_dataset1_table1_set2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table1_set2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table1_set1 = L3_dataset1_table1_set1[cols_list_set1]\n",
    "L3_dataset1_table1_set2 = L3_dataset1_table1_set2[cols_list_set2]\n",
    "# Load Table2.csv\n",
    "L3_dataset1_table2_raw = pd.read_csv(\"L3_collaboration_data/dataset1/Table2.csv\", skiprows = 11)\n",
    "L3_dataset1_table2_set1 = L3_dataset1_table2_raw[:][:6]\n",
    "L3_dataset1_table2_set2 = L3_dataset1_table2_raw[:][10:]\n",
    "L3_dataset1_table2_set2.columns = ['X', 'X LOW', 'X HIGH', 'F2(C=SET2)/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']\n",
    "L3_dataset1_table2_set1[\"Q**2 [GEV**2]\"] = 5.0\n",
    "L3_dataset1_table2_set1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table2_set1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table2_set2[\"Q**2 [GEV**2]\"] = 5.0\n",
    "L3_dataset1_table2_set2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table2_set2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table2_set1 = L3_dataset1_table2_set1[cols_list_set1]\n",
    "L3_dataset1_table2_set2 = L3_dataset1_table2_set2[cols_list_set2]\n",
    "# Load Table3.csv\n",
    "L3_dataset1_table3_raw = pd.read_csv(\"L3_collaboration_data/dataset1/Table3.csv\", skiprows = 11)\n",
    "# Load set1\n",
    "L3_dataset1_table3_set1 = L3_dataset1_table3_raw[:][:4]\n",
    "L3_dataset1_table3_set1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table3_set1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table3_set1[\"X\"] = 0.5 * (0.01 + 0.1)\n",
    "L3_dataset1_table3_set1[\"X LOW\"] = 0.01\n",
    "L3_dataset1_table3_set1[\"X HIGH\"] = 0.1\n",
    "L3_dataset1_table3_set1.columns = [\"Q**2 [GEV**2]\",'F2(C=SET1)/ALPHA', 'stat +', 'stat -', 'sys +', 'sys -',\n",
    "                                   \"Q**2 [GEV**2] LOW\",\"Q**2 [GEV**2] HIGH\", 'X', 'X LOW', 'X HIGH']\n",
    "L3_dataset1_table3_set1 = L3_dataset1_table3_set1[cols_list_set1]\n",
    "# Load set2\n",
    "L3_dataset1_table3_set2 = L3_dataset1_table3_raw[:][8:]\n",
    "L3_dataset1_table3_set2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "L3_dataset1_table3_set2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "L3_dataset1_table3_set2[\"X\"] = 0.5 * (0.01 + 0.1)\n",
    "L3_dataset1_table3_set2[\"X LOW\"] = 0.01\n",
    "L3_dataset1_table3_set2[\"X HIGH\"] = 0.1\n",
    "L3_dataset1_table3_set2.columns = [\"Q**2 [GEV**2]\",'F2(C=SET2)/ALPHA', 'stat +', 'stat -', 'sys +', 'sys -',\n",
    "                                   \"Q**2 [GEV**2] LOW\",\"Q**2 [GEV**2] HIGH\", 'X', 'X LOW', 'X HIGH']\n",
    "L3_dataset1_table3_set2 = L3_dataset1_table3_set2[cols_list_set2]\n",
    "# Dataset 2\n",
    "# Table1.csv\n",
    "L3_dataset2_table1_raw = pd.read_csv(\"L3_collaboration_data/dataset2/Table1.csv\", skiprows = 12)\n",
    "L3_dataset2_table1_set1 = L3_dataset2_table1_raw[:][:3]\n",
    "L3_dataset2_table1_set1[\"Q**2 [GEV**2]\"] = 10.8\n",
    "L3_dataset2_table1_set1[\"Q**2 [GEV**2] LOW\"] = 9.0\n",
    "L3_dataset2_table1_set1[\"Q**2 [GEV**2] HIGH\"] = 13.0\n",
    "L3_dataset2_table1_set1 = L3_dataset2_table1_set1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys_1 +',\n",
    "       'sys_1 -', 'sys_2 +', 'sys_2 -']]\n",
    "L3_dataset2_table1_set2 = L3_dataset2_table1_raw[:][8:12]\n",
    "L3_dataset2_table1_set2[\"Q**2 [GEV**2]\"] = 15.3\n",
    "L3_dataset2_table1_set2[\"Q**2 [GEV**2] LOW\"] = 13.0\n",
    "L3_dataset2_table1_set2[\"Q**2 [GEV**2] HIGH\"] = 18.0\n",
    "L3_dataset2_table1_set2 = L3_dataset2_table1_set2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys_1 +',\n",
    "       'sys_1 -', 'sys_2 +', 'sys_2 -']]\n",
    "L3_dataset2_table1_set3 = L3_dataset2_table1_raw[:][16:]\n",
    "L3_dataset2_table1_set3[\"Q**2 [GEV**2]\"] = 23.1\n",
    "L3_dataset2_table1_set3[\"Q**2 [GEV**2] LOW\"] = 18.0\n",
    "L3_dataset2_table1_set3[\"Q**2 [GEV**2] HIGH\"] = 30.0\n",
    "L3_dataset2_table1_set3 = L3_dataset2_table1_set3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys_1 +',\n",
    "       'sys_1 -', 'sys_2 +', 'sys_2 -']]\n",
    "# Dataset3\n",
    "# Table1.csv\n",
    "L3_dataset3_table1 = pd.read_csv(\"L3_collaboration_data/dataset3/Table1.csv\", skiprows = 12)\n",
    "L3_dataset3_table1[\"Q**2 [GEV**2]\"] = 120.0\n",
    "L3_dataset3_table1[\"Q**2 [GEV**2] LOW\"] = 50.0\n",
    "L3_dataset3_table1[\"Q**2 [GEV**2] HIGH\"] = 400.0\n",
    "L3_dataset3_table1 = L3_dataset3_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table2.csv\n",
    "L3_dataset3_table2_raw = pd.read_csv(\"L3_collaboration_data/dataset3/Table2.csv\", skiprows = 12)\n",
    "L3_dataset3_table2_set1 = L3_dataset3_table2_raw[:][:4]\n",
    "L3_dataset3_table2_set1[\"X\"] = (0.05 + 0.98) / 2\n",
    "L3_dataset3_table2_set1[\"X LOW\"] = 0.05\n",
    "L3_dataset3_table2_set1[\"X HIGH\"] = 0.98\n",
    "L3_dataset3_table2_set1[\"Q**2 [GEV**2] LOW\"] = 0\n",
    "L3_dataset3_table2_set1[\"Q**2 [GEV**2] HIGH\"] = 0\n",
    "L3_dataset3_table2_set1 = L3_dataset3_table2_set1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "L3_dataset3_table2_set2 = L3_dataset3_table2_raw[:][9:13]\n",
    "L3_dataset3_table2_set2[\"X\"] = (0.3 + 0.8) / 2\n",
    "L3_dataset3_table2_set2[\"X LOW\"] = 0.3\n",
    "L3_dataset3_table2_set2[\"X HIGH\"] = 0.8\n",
    "L3_dataset3_table2_set2[\"Q**2 [GEV**2] LOW\"] = 0\n",
    "L3_dataset3_table2_set2[\"Q**2 [GEV**2] HIGH\"] = 0\n",
    "L3_dataset3_table2_set2 = L3_dataset3_table2_set2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "L3_dataset3_table2_set3 = L3_dataset3_table2_raw[:][18:22]\n",
    "L3_dataset3_table2_set3[\"X\"] = (0.1 + 0.6) / 2\n",
    "L3_dataset3_table2_set3[\"X LOW\"] = 0.1\n",
    "L3_dataset3_table2_set3[\"X HIGH\"] = 0.6\n",
    "L3_dataset3_table2_set3[\"Q**2 [GEV**2] LOW\"] = 0\n",
    "L3_dataset3_table2_set3[\"Q**2 [GEV**2] HIGH\"] = 0\n",
    "L3_dataset3_table2_set3 = L3_dataset3_table2_set3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPAL data\n",
    "# Dataset1\n",
    "# Table1.csv\n",
    "OPAL_dataset1_table1 = pd.read_csv(\"OPAL_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "OPAL_dataset1_table1[\"Q**2 [GEV**2]\"] = 7.5\n",
    "OPAL_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset1_table1 = OPAL_dataset1_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table2.csv\n",
    "OPAL_dataset1_table2 = pd.read_csv(\"OPAL_collaboration_data/dataset1/Table2.csv\", skiprows = 11)\n",
    "OPAL_dataset1_table2[\"Q**2 [GEV**2]\"] = 14.7\n",
    "OPAL_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset1_table2 = OPAL_dataset1_table2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table3.csv\n",
    "OPAL_dataset1_table3 = pd.read_csv(\"OPAL_collaboration_data/dataset1/Table3.csv\", skiprows = 11)\n",
    "OPAL_dataset1_table3[\"Q**2 [GEV**2]\"] = 135.0\n",
    "OPAL_dataset1_table3[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset1_table3[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset1_table3 = OPAL_dataset1_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table4.csv\n",
    "OPAL_dataset1_table4 = pd.read_csv(\"OPAL_collaboration_data/dataset1/Table4.csv\", skiprows = 12)\n",
    "OPAL_dataset1_table4[\"Q**2 [GEV**2] LOW\"] = 6.0\n",
    "OPAL_dataset1_table4[\"Q**2 [GEV**2] HIGH\"] = 400.0\n",
    "OPAL_dataset1_table4[\"X\"] = (0.1 + 0.6) / 2\n",
    "OPAL_dataset1_table4[\"X LOW\"] = 0.1\n",
    "OPAL_dataset1_table4[\"X HIGH\"] = 0.6\n",
    "OPAL_dataset1_table4 = OPAL_dataset1_table4[['X', 'X LOW', 'X HIGH', 'Q2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset1_table4.columns = ['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']\n",
    "# Dataset2\n",
    "# Table1.csv\n",
    "OPAL_dataset2_table1_raw = pd.read_csv(\"OPAL_collaboration_data/dataset2/Table1.csv\", skiprows = 13)\n",
    "OPAL_dataset2_table1_set1 = OPAL_dataset2_table1_raw[:][:3]\n",
    "OPAL_dataset2_table1_set1[\"Q**2 [GEV**2]\"] = 9.0\n",
    "OPAL_dataset2_table1_set1[\"Q**2 [GEV**2] LOW\"] = 6.0\n",
    "OPAL_dataset2_table1_set1[\"Q**2 [GEV**2] HIGH\"] = 11.0\n",
    "OPAL_dataset2_table1_set1 = OPAL_dataset2_table1_set1[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "OPAL_dataset2_table1_set2 = OPAL_dataset2_table1_raw[:][8:11]\n",
    "OPAL_dataset2_table1_set2[\"Q**2 [GEV**2]\"] = 14.5\n",
    "OPAL_dataset2_table1_set2[\"Q**2 [GEV**2] LOW\"] = 11.0\n",
    "OPAL_dataset2_table1_set2[\"Q**2 [GEV**2] HIGH\"] = 20.0\n",
    "OPAL_dataset2_table1_set2 = OPAL_dataset2_table1_set2[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "OPAL_dataset2_table1_set3 = OPAL_dataset2_table1_raw[:][16:]\n",
    "OPAL_dataset2_table1_set3[\"Q**2 [GEV**2]\"] = 11.0\n",
    "OPAL_dataset2_table1_set3[\"Q**2 [GEV**2] LOW\"] = 6.0\n",
    "OPAL_dataset2_table1_set3[\"Q**2 [GEV**2] HIGH\"] = 20.0\n",
    "OPAL_dataset2_table1_set3 = OPAL_dataset2_table1_set3[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table2.csv\n",
    "OPAL_dataset2_table2_raw = pd.read_csv(\"OPAL_collaboration_data/dataset2/Table2.csv\", skiprows = 13)\n",
    "OPAL_dataset2_table2_set1 = OPAL_dataset2_table2_raw[:][:4]\n",
    "OPAL_dataset2_table2_set1[\"Q**2 [GEV**2]\"] = 30.0\n",
    "OPAL_dataset2_table2_set1[\"Q**2 [GEV**2] LOW\"] = 20.0\n",
    "OPAL_dataset2_table2_set1[\"Q**2 [GEV**2] HIGH\"] = 40.0\n",
    "OPAL_dataset2_table2_set1 = OPAL_dataset2_table2_set1[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "OPAL_dataset2_table2_set2 = OPAL_dataset2_table2_raw[:][9:13]\n",
    "OPAL_dataset2_table2_set2[\"Q**2 [GEV**2]\"] = 59.0\n",
    "OPAL_dataset2_table2_set2[\"Q**2 [GEV**2] LOW\"] = 40.0\n",
    "OPAL_dataset2_table2_set2[\"Q**2 [GEV**2] HIGH\"] = 100.0\n",
    "OPAL_dataset2_table2_set2 = OPAL_dataset2_table2_set2[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "OPAL_dataset2_table2_set3 = OPAL_dataset2_table2_raw[:][18:]\n",
    "OPAL_dataset2_table2_set3[\"Q**2 [GEV**2]\"] = 41.0\n",
    "OPAL_dataset2_table2_set3[\"Q**2 [GEV**2] LOW\"] = 20.0\n",
    "OPAL_dataset2_table2_set3[\"Q**2 [GEV**2] HIGH\"] = 100.0\n",
    "OPAL_dataset2_table2_set3 = OPAL_dataset2_table2_set3[['X', 'X LOW', 'X HIGH', \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table3.csv\n",
    "OPAL_dataset2_table3 = pd.read_csv(\"OPAL_collaboration_data/dataset2/Table3.csv\", skiprows = 13)\n",
    "OPAL_dataset2_table3 = OPAL_dataset2_table3[:][4:]\n",
    "OPAL_dataset2_table3[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table3[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table3[\"X\"] = (0.1 + 0.6) / 2\n",
    "OPAL_dataset2_table3[\"X LOW\"] = 0.1\n",
    "OPAL_dataset2_table3[\"X HIGH\"] = 0.6\n",
    "OPAL_dataset2_table3 = OPAL_dataset2_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Table4.csv\n",
    "OPAL_dataset2_table4_raw = pd.read_csv(\"OPAL_collaboration_data/dataset2/Table4.csv\", skiprows = 13) \n",
    "OPAL_dataset2_table4_set1 = OPAL_dataset2_table4_raw[:][:4]\n",
    "OPAL_dataset2_table4_set1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set1[\"X\"] = (0.02 + 0.1) / 2\n",
    "OPAL_dataset2_table4_set1[\"X LOW\"] = 0.02\n",
    "OPAL_dataset2_table4_set1[\"X HIGH\"] = 0.1\n",
    "OPAL_dataset2_table4_set1 = OPAL_dataset2_table4_set1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset2_table4_set2 = OPAL_dataset2_table4_raw[:][6:7]\n",
    "OPAL_dataset2_table4_set2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set2[\"X\"] = (0.02 + 0.1) / 2\n",
    "OPAL_dataset2_table4_set2[\"X LOW\"] = 0.02\n",
    "OPAL_dataset2_table4_set2[\"X HIGH\"] = 0.1\n",
    "OPAL_dataset2_table4_set2 = OPAL_dataset2_table4_set2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset2_table4_set3 = OPAL_dataset2_table4_raw[:][13:17]\n",
    "OPAL_dataset2_table4_set3[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set3[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set3[\"X\"] = (0.1 + 0.25) / 2\n",
    "OPAL_dataset2_table4_set3[\"X LOW\"] = 0.1\n",
    "OPAL_dataset2_table4_set3[\"X HIGH\"] = 0.25\n",
    "OPAL_dataset2_table4_set3 = OPAL_dataset2_table4_set3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset2_table4_set4 = OPAL_dataset2_table4_raw[:][18:19]\n",
    "OPAL_dataset2_table4_set4[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set4[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set4[\"X\"] = (0.1 + 0.25) / 2\n",
    "OPAL_dataset2_table4_set4[\"X LOW\"] = 0.1\n",
    "OPAL_dataset2_table4_set4[\"X HIGH\"] = 0.25\n",
    "OPAL_dataset2_table4_set4 = OPAL_dataset2_table4_set4[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset2_table4_set5 = OPAL_dataset2_table4_raw[:][26:29]\n",
    "OPAL_dataset2_table4_set5[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set5[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set5[\"X\"] = (0.25 + 0.6) / 2\n",
    "OPAL_dataset2_table4_set5[\"X LOW\"] = 0.25\n",
    "OPAL_dataset2_table4_set5[\"X HIGH\"] = 0.6\n",
    "OPAL_dataset2_table4_set5 = OPAL_dataset2_table4_set5[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "OPAL_dataset2_table4_set6 = OPAL_dataset2_table4_raw[:][30:]\n",
    "OPAL_dataset2_table4_set6[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset2_table4_set6[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset2_table4_set6[\"X\"] = (0.25 + 0.6) / 2\n",
    "OPAL_dataset2_table4_set6[\"X LOW\"] = 0.25\n",
    "OPAL_dataset2_table4_set6[\"X HIGH\"] = 0.6\n",
    "OPAL_dataset2_table4_set6 = OPAL_dataset2_table4_set6[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']]\n",
    "# Dataset3\n",
    "# Table1.csv\n",
    "OPAL_dataset3_table1_raw = pd.read_csv(\"OPAL_collaboration_data/dataset3/Table1.csv\", skiprows = 12) \n",
    "OPAL_dataset3_table1_raw[\"Q**2 [GEV**2]\"] = 1.86\n",
    "OPAL_dataset3_table1_raw[\"Q**2 [GEV**2] LOW\"] = 1.1\n",
    "OPAL_dataset3_table1_raw[\"Q**2 [GEV**2] HIGH\"] = 2.5\n",
    "OPAL_dataset3_table1 = OPAL_dataset3_table1_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table2.csv\n",
    "OPAL_dataset3_table2_raw = pd.read_csv(\"OPAL_collaboration_data/dataset3/Table2.csv\", skiprows = 12)\n",
    "OPAL_dataset3_table2_raw[\"Q**2 [GEV**2]\"] = 3.76\n",
    "OPAL_dataset3_table2_raw[\"Q**2 [GEV**2] LOW\"] = 2.5\n",
    "OPAL_dataset3_table2_raw[\"Q**2 [GEV**2] HIGH\"] = 6.6\n",
    "OPAL_dataset3_table2 = OPAL_dataset3_table2_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "\n",
    "# Dataset4\n",
    "# Table1.csv\n",
    "OPAL_dataset4_table1_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table1.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table1_raw[\"Q**2 [GEV**2]\"] = 1.9\n",
    "OPAL_dataset4_table1_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table1_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table1 = OPAL_dataset4_table1_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table2.csv\n",
    "OPAL_dataset4_table2_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table2.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table2_raw[\"Q**2 [GEV**2]\"] = 3.7\n",
    "OPAL_dataset4_table2_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table2_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table2 = OPAL_dataset4_table2_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table3.csv\n",
    "OPAL_dataset4_table3_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table3.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table3_raw[\"Q**2 [GEV**2]\"] = 8.9\n",
    "OPAL_dataset4_table3_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table3_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table3 = OPAL_dataset4_table3_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table4.csv\n",
    "OPAL_dataset4_table4_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table4.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table4_raw[\"Q**2 [GEV**2]\"] = 10.7\n",
    "OPAL_dataset4_table4_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table4_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table4 = OPAL_dataset4_table4_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table5.csv\n",
    "OPAL_dataset4_table5_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table5.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table5_raw[\"Q**2 [GEV**2]\"] = 17.5\n",
    "OPAL_dataset4_table5_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table5_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table5 = OPAL_dataset4_table5_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table6.csv\n",
    "OPAL_dataset4_table6_raw = pd.read_csv(\"OPAL_collaboration_data/dataset4/Table6.csv\", skiprows = 13) \n",
    "OPAL_dataset4_table6_raw[\"Q**2 [GEV**2]\"] = 17.8\n",
    "OPAL_dataset4_table6_raw[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "OPAL_dataset4_table6_raw[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "OPAL_dataset4_table6 = OPAL_dataset4_table6_raw[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHAE', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "\n",
    "# Dataset5\n",
    "# Table1.csv\n",
    "OPAL_dataset5_table1_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table1.csv\", skiprows = 14) \n",
    "OPAL_dataset5_table1 = OPAL_dataset5_table1_raw[:][:3]\n",
    "OPAL_dataset5_table1[\"Q**2 [GEV**2]\"] = 780.0\n",
    "OPAL_dataset5_table1[\"Q**2 [GEV**2] LOW\"] = 400.0\n",
    "OPAL_dataset5_table1[\"Q**2 [GEV**2] HIGH\"] = 2350.0\n",
    "OPAL_dataset5_table1 = OPAL_dataset5_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table3.csv\n",
    "OPAL_dataset5_table3_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table3.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table3 = OPAL_dataset5_table3_raw[:][:2]\n",
    "OPAL_dataset5_table3[\"Q**2 [GEV**2]\"] = 12.1\n",
    "OPAL_dataset5_table3[\"Q**2 [GEV**2] LOW\"] = 9.0\n",
    "OPAL_dataset5_table3[\"Q**2 [GEV**2] HIGH\"] = 15.0\n",
    "OPAL_dataset5_table3 = OPAL_dataset5_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table4.csv\n",
    "OPAL_dataset5_table4_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table4.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table4 = OPAL_dataset5_table4_raw[:][:2]\n",
    "OPAL_dataset5_table4[\"Q**2 [GEV**2]\"] = 19.9\n",
    "OPAL_dataset5_table4[\"Q**2 [GEV**2] LOW\"] = 15.0\n",
    "OPAL_dataset5_table4[\"Q**2 [GEV**2] HIGH\"] = 30.0\n",
    "OPAL_dataset5_table4 = OPAL_dataset5_table4[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table5.csv\n",
    "OPAL_dataset5_table5_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table5.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table5 = OPAL_dataset5_table5_raw[:][:3]\n",
    "OPAL_dataset5_table5[\"Q**2 [GEV**2]\"] = 39.7\n",
    "OPAL_dataset5_table5[\"Q**2 [GEV**2] LOW\"] = 30.0\n",
    "OPAL_dataset5_table5[\"Q**2 [GEV**2] HIGH\"] = 50.0\n",
    "OPAL_dataset5_table5 = OPAL_dataset5_table5[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table6.csv\n",
    "OPAL_dataset5_table6_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table6.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table6 = OPAL_dataset5_table6_raw[:][:3]\n",
    "OPAL_dataset5_table6[\"Q**2 [GEV**2]\"] = 76.4\n",
    "OPAL_dataset5_table6[\"Q**2 [GEV**2] LOW\"] = 50.0\n",
    "OPAL_dataset5_table6[\"Q**2 [GEV**2] HIGH\"] = 150.0\n",
    "OPAL_dataset5_table6 = OPAL_dataset5_table6[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table7.csv\n",
    "OPAL_dataset5_table7_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table7.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table7 = OPAL_dataset5_table7_raw[:][:2]\n",
    "OPAL_dataset5_table7[\"Q**2 [GEV**2]\"] = 780.0\n",
    "OPAL_dataset5_table7[\"Q**2 [GEV**2] LOW\"] = 400.0\n",
    "OPAL_dataset5_table7[\"Q**2 [GEV**2] HIGH\"] = 2350.0\n",
    "OPAL_dataset5_table7 = OPAL_dataset5_table7[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table13.csv\n",
    "OPAL_dataset5_table13_raw = pd.read_csv(\"OPAL_collaboration_data/dataset5/Table13.csv\", skiprows = 12) \n",
    "OPAL_dataset5_table13 = OPAL_dataset5_table13_raw[:][:5]\n",
    "OPAL_dataset5_table13[\"X\"] = 0.5 * (0.1 + 0.6)\n",
    "OPAL_dataset5_table13[\"X LOW\"] = 0.1\n",
    "OPAL_dataset5_table13[\"X HIGH\"] = 0.6\n",
    "OPAL_dataset5_table13 = OPAL_dataset5_table13[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AMY data\n",
    "# Dataset1\n",
    "# Table1.csv\n",
    "AMY_dataset1_table1 = pd.read_csv(\"AMY_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "AMY_dataset1_table1[\"X LOW\"] = 0.0\n",
    "AMY_dataset1_table1[\"X HIGH\"] = 0.0\n",
    "AMY_dataset1_table1[\"Q**2 [GEV**2]\"] = 73.0\n",
    "AMY_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "AMY_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "AMY_dataset1_table1 = AMY_dataset1_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table2.csv\n",
    "AMY_dataset1_table2 = pd.read_csv(\"AMY_collaboration_data/dataset1/Table2.csv\", skiprows = 11)\n",
    "AMY_dataset1_table2[\"X LOW\"] = 0.0\n",
    "AMY_dataset1_table2[\"X HIGH\"] = 0.0\n",
    "AMY_dataset1_table2[\"Q**2 [GEV**2]\"] = 390.0\n",
    "AMY_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "AMY_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "AMY_dataset1_table2 = AMY_dataset1_table2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table3.csv\n",
    "AMY_dataset1_table3 = pd.read_csv(\"AMY_collaboration_data/dataset1/Table3.csv\", skiprows = 12)\n",
    "AMY_dataset1_table3[\"X\"] = 0.5 * (0.3 + 0.8)\n",
    "AMY_dataset1_table3[\"X LOW\"] = 0.3\n",
    "AMY_dataset1_table3[\"X HIGH\"] = 0.8\n",
    "AMY_dataset1_table3[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "AMY_dataset1_table3[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "AMY_dataset1_table3 = AMY_dataset1_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +','error -']]\n",
    "# Dataset2\n",
    "# Table1.csv\n",
    "AMY_dataset2_table1 = pd.read_csv(\"AMY_collaboration_data/dataset2/Table1.csv\", skiprows = 11)\n",
    "AMY_dataset2_table1[\"Q**2 [GEV**2]\"] = 6.8\n",
    "AMY_dataset2_table1[\"Q**2 [GEV**2] LOW\"] = 3.5\n",
    "AMY_dataset2_table1[\"Q**2 [GEV**2] HIGH\"] = 12\n",
    "AMY_dataset2_table1 = AMY_dataset2_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +','sys -']]\n",
    "# Table2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PLUTO data\n",
    "# Dataset1\n",
    "# Table1.csv\n",
    "PLUTO_dataset1_table1_raw = pd.read_csv(\"PLUTO_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "PLUTO_dataset1_table1 = PLUTO_dataset1_table1_raw[:][:3]\n",
    "PLUTO_dataset1_table1[\"Q**2 [GEV**2]\"] = 2.4\n",
    "PLUTO_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 1.5\n",
    "PLUTO_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 3\n",
    "PLUTO_dataset1_table1 = PLUTO_dataset1_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "PLUTO_dataset1_table1_without_charm = PLUTO_dataset1_table1_raw[:][7:]\n",
    "PLUTO_dataset1_table1_without_charm[\"Q**2 [GEV**2]\"] = 2.4\n",
    "PLUTO_dataset1_table1_without_charm[\"Q**2 [GEV**2] LOW\"] = 1.5\n",
    "PLUTO_dataset1_table1_without_charm[\"Q**2 [GEV**2] HIGH\"] = 3\n",
    "PLUTO_dataset1_table1_without_charm = PLUTO_dataset1_table1_without_charm[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Table2.csv\n",
    "PLUTO_dataset1_table2_raw = pd.read_csv(\"PLUTO_collaboration_data/dataset1/Table2.csv\", skiprows = 11)\n",
    "PLUTO_dataset1_table2 = PLUTO_dataset1_table2_raw[:][:3]\n",
    "PLUTO_dataset1_table2[\"Q**2 [GEV**2]\"] = 4.3\n",
    "PLUTO_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 3\n",
    "PLUTO_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 6\n",
    "PLUTO_dataset1_table2 = PLUTO_dataset1_table2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "PLUTO_dataset1_table2_without_charm = PLUTO_dataset1_table2_raw[:][7:]\n",
    "PLUTO_dataset1_table2_without_charm[\"Q**2 [GEV**2]\"] = 4.3\n",
    "PLUTO_dataset1_table2_without_charm[\"Q**2 [GEV**2] LOW\"] = 3\n",
    "PLUTO_dataset1_table2_without_charm[\"Q**2 [GEV**2] HIGH\"] = 6\n",
    "PLUTO_dataset1_table2_without_charm = PLUTO_dataset1_table2_without_charm[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Table3.csv\n",
    "PLUTO_dataset1_table3_raw = pd.read_csv(\"PLUTO_collaboration_data/dataset1/Table3.csv\", skiprows = 11)\n",
    "PLUTO_dataset1_table3 = PLUTO_dataset1_table3_raw[:][:3]\n",
    "PLUTO_dataset1_table3[\"Q**2 [GEV**2]\"] = 9.2\n",
    "PLUTO_dataset1_table3[\"Q**2 [GEV**2] LOW\"] = 6\n",
    "PLUTO_dataset1_table3[\"Q**2 [GEV**2] HIGH\"] = 16\n",
    "PLUTO_dataset1_table3 = PLUTO_dataset1_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "PLUTO_dataset1_table3_without_charm = PLUTO_dataset1_table3_raw[:][7:]\n",
    "PLUTO_dataset1_table3_without_charm[\"Q**2 [GEV**2]\"] = 9.2\n",
    "PLUTO_dataset1_table3_without_charm[\"Q**2 [GEV**2] LOW\"] = 6\n",
    "PLUTO_dataset1_table3_without_charm[\"Q**2 [GEV**2] HIGH\"] = 16\n",
    "PLUTO_dataset1_table3_without_charm = PLUTO_dataset1_table3_without_charm[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Table4.csv\n",
    "PLUTO_dataset1_table4_raw = pd.read_csv(\"PLUTO_collaboration_data/dataset1/Table4.csv\", skiprows = 11)\n",
    "PLUTO_dataset1_table4 = PLUTO_dataset1_table4_raw[:][:6]\n",
    "PLUTO_dataset1_table4[\"Q**2 [GEV**2]\"] = 5.3\n",
    "PLUTO_dataset1_table4[\"Q**2 [GEV**2] LOW\"] = 1.5\n",
    "PLUTO_dataset1_table4[\"Q**2 [GEV**2] HIGH\"] = 16\n",
    "PLUTO_dataset1_table4 = PLUTO_dataset1_table4[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "PLUTO_dataset1_table4_without_charm = PLUTO_dataset1_table4_raw[:][10:]\n",
    "PLUTO_dataset1_table4_without_charm[\"Q**2 [GEV**2]\"] = 5.3\n",
    "PLUTO_dataset1_table4_without_charm[\"Q**2 [GEV**2] LOW\"] = 1.5\n",
    "PLUTO_dataset1_table4_without_charm[\"Q**2 [GEV**2] HIGH\"] = 16\n",
    "PLUTO_dataset1_table4_without_charm = PLUTO_dataset1_table4_without_charm[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Dataset2\n",
    "# Table1.csv\n",
    "PLUTO_dataset2_table1 = pd.read_csv(\"PLUTO_collaboration_data/dataset2/Table1.csv\", skiprows = 12)\n",
    "PLUTO_dataset2_table1[\"Q**2 [GEV**2]\"] = 45.0\n",
    "PLUTO_dataset2_table1[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "PLUTO_dataset2_table1[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "PLUTO_dataset2_table1 = PLUTO_dataset2_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Table2.csv\n",
    "PLUTO_dataset2_table2 = pd.read_csv(\"PLUTO_collaboration_data/dataset2/Table2.csv\", skiprows = 12)\n",
    "PLUTO_dataset2_table2[\"Q**2 [GEV**2]\"] = 45.0\n",
    "PLUTO_dataset2_table2[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "PLUTO_dataset2_table2[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "PLUTO_dataset2_table2 = PLUTO_dataset2_table2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA(C=MINUS CHARM)', 'error +', 'error -']]\n",
    "# Table3.csv\n",
    "PLUTO_dataset2_table3 = pd.read_csv(\"PLUTO_collaboration_data/dataset2/Table3.csv\", skiprows = 12)\n",
    "PLUTO_dataset2_table3[\"X\"] = 0.5 * (0.3 + 0.8)\n",
    "PLUTO_dataset2_table3[\"X LOW\"] = 0.3\n",
    "PLUTO_dataset2_table3[\"X HIGH\"] = 0.8\n",
    "PLUTO_dataset2_table3[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "PLUTO_dataset2_table3[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "PLUTO_dataset2_table3 = PLUTO_dataset2_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA(C=MINUS CHARM)', 'error +', 'error -']]\n",
    "# Table4.csv\n",
    "PLUTO_dataset2_table4 = pd.read_csv(\"PLUTO_collaboration_data/dataset2/Table4.csv\", skiprows = 12)\n",
    "PLUTO_dataset2_table4[\"Q**2 [GEV**2]\"] = 4.3\n",
    "PLUTO_dataset2_table4[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "PLUTO_dataset2_table4[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "PLUTO_dataset2_table4 = PLUTO_dataset2_table4[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA(C=MINUS CHARM)', 'error +', 'error -']]\n",
    "# Table5.csv\n",
    "PLUTO_dataset2_table5 = pd.read_csv(\"PLUTO_collaboration_data/dataset2/Table5.csv\", skiprows = 12)\n",
    "PLUTO_dataset2_table5[\"Q**2 [GEV**2]\"] = 9.2\n",
    "PLUTO_dataset2_table5[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "PLUTO_dataset2_table5[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "PLUTO_dataset2_table5 = PLUTO_dataset2_table5[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA(C=MINUS CHARM)', 'error +', 'error -']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TASSO data\n",
    "# Dataset1\n",
    "# Table1.csv\n",
    "TASSO_dataset1_table1_raw = pd.read_csv(\"TASSO_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "TASSO_dataset1_table1 = TASSO_dataset1_table1_raw[:][:5]\n",
    "TASSO_dataset1_table1[\"Q**2 [GEV**2]\"] = 23.0\n",
    "TASSO_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 7.0\n",
    "TASSO_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 70.0\n",
    "TASSO_dataset1_table1 = TASSO_dataset1_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "TASSO_dataset1_table1_without_charm = TASSO_dataset1_table1_raw[:][9:]\n",
    "TASSO_dataset1_table1_without_charm[\"Q**2 [GEV**2]\"] = 23.0\n",
    "TASSO_dataset1_table1_without_charm[\"Q**2 [GEV**2] LOW\"] = 7.0\n",
    "TASSO_dataset1_table1_without_charm[\"Q**2 [GEV**2] HIGH\"] = 70.0\n",
    "TASSO_dataset1_table1_without_charm = TASSO_dataset1_table1_without_charm[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TOPAZ data\n",
    "# Dataset1\n",
    "# Table1.csv\n",
    "TOPAZ_dataset1_table1 = pd.read_csv(\"TOPAZ_collaboration_data/dataset1/Table1.csv\", skiprows = 11)\n",
    "TOPAZ_dataset1_table1[\"Q**2 [GEV**2]\"] = 5.1\n",
    "TOPAZ_dataset1_table1[\"Q**2 [GEV**2] LOW\"] = 3.0\n",
    "TOPAZ_dataset1_table1[\"Q**2 [GEV**2] HIGH\"] = 10.0\n",
    "TOPAZ_dataset1_table1 = TOPAZ_dataset1_table1[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +', 'sys -']]\n",
    "# Table2.csv\n",
    "TOPAZ_dataset1_table2 = pd.read_csv(\"TOPAZ_collaboration_data/dataset1/Table2.csv\", skiprows = 11)\n",
    "TOPAZ_dataset1_table2[\"Q**2 [GEV**2]\"] = 16.0\n",
    "TOPAZ_dataset1_table2[\"Q**2 [GEV**2] LOW\"] = 10.0\n",
    "TOPAZ_dataset1_table2[\"Q**2 [GEV**2] HIGH\"] = 30.0\n",
    "TOPAZ_dataset1_table2 = TOPAZ_dataset1_table2[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +', 'sys -']]\n",
    "# Table3.csv\n",
    "TOPAZ_dataset1_table3 = pd.read_csv(\"TOPAZ_collaboration_data/dataset1/Table3.csv\", skiprows = 11)\n",
    "TOPAZ_dataset1_table3[\"Q**2 [GEV**2]\"] = 80.0\n",
    "TOPAZ_dataset1_table3[\"Q**2 [GEV**2] LOW\"] = 45.0\n",
    "TOPAZ_dataset1_table3[\"Q**2 [GEV**2] HIGH\"] = 130.0\n",
    "TOPAZ_dataset1_table3 = TOPAZ_dataset1_table3[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'stat +', 'stat -', 'sys +', 'sys -']]\n",
    "# Table4.csv\n",
    "TOPAZ_dataset1_table4 = pd.read_csv(\"TOPAZ_collaboration_data/dataset1/Table4.csv\", skiprows = 12)\n",
    "TOPAZ_dataset1_table4[\"X\"] = 0.5 * (0.3+0.8)\n",
    "TOPAZ_dataset1_table4[\"X LOW\"] = 0.3\n",
    "TOPAZ_dataset1_table4[\"X HIGH\"] = 0.8\n",
    "TOPAZ_dataset1_table4[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "TOPAZ_dataset1_table4[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "TOPAZ_dataset1_table4 = TOPAZ_dataset1_table4[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]\n",
    "# Table5.csv\n",
    "TOPAZ_dataset1_table5_light_quarks = pd.read_csv(\"TOPAZ_collaboration_data/dataset1/Table5.csv\", skiprows = 12)\n",
    "TOPAZ_dataset1_table5_light_quarks[\"X\"] = 0.5 * (0.3+0.8)\n",
    "TOPAZ_dataset1_table5_light_quarks[\"X LOW\"] = 0.3\n",
    "TOPAZ_dataset1_table5_light_quarks[\"X HIGH\"] = 0.8\n",
    "TOPAZ_dataset1_table5_light_quarks[\"Q**2 [GEV**2] LOW\"] = 0.0\n",
    "TOPAZ_dataset1_table5_light_quarks[\"Q**2 [GEV**2] HIGH\"] = 0.0\n",
    "TOPAZ_dataset1_table5_light_quarks = TOPAZ_dataset1_table5_light_quarks[['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW', 'Q**2 [GEV**2] HIGH', 'F2/ALPHA', 'error +', 'error -']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "# ALEPH data\n",
    "ALEPH_list = [ALEPH_dataset1_table4, ALEPH_dataset1_table6, ALEPH_dataset1_table8]\n",
    "ALEPH_list2 = [ALEPH_dataset2_table1, ALEPH_dataset2_table2]\n",
    "ALEPH_dataset1 = mergeDataSets(ALEPH_list)\n",
    "ALEPH_dataset2 = mergeDataSets(ALEPH_list2)\n",
    "# DELPHI data\n",
    "DELPHI_list = [DELPHI_dataset1_table1, DELPHI_dataset1_table2]\n",
    "DELPHI_data = mergeDataSets(DELPHI_list)\n",
    "# TPC data\n",
    "TPC_list = [TPC_dataset1_table1, TPC_dataset1_table2, TPC_dataset1_table3, TPC_dataset1_table4, \n",
    "            TPC_dataset1_table5, TPC_dataset1_table6, TPC_dataset1_table7, TPC_dataset1_table8, \n",
    "           TPC_dataset1_table9, TPC_dataset1_table10, TPC_dataset1_table11]\n",
    "TPC_data = mergeDataSets(TPC_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge L3 data from dataset1\n",
    "L3_dataset1_list = [L3_dataset1_table1_set1, L3_dataset1_table1_set2, L3_dataset1_table2_set1,\n",
    "                   L3_dataset1_table2_set2, L3_dataset1_table3_set1, L3_dataset1_table3_set2]\n",
    "L3_dataset1_set1_list = [L3_dataset1_table1_set1, L3_dataset1_table2_set1, L3_dataset1_table3_set1]\n",
    "L3_dataset1_set1 = mergeDataSets(L3_dataset1_set1_list)\n",
    "L3_dataset1_set2_list = [L3_dataset1_table1_set2, L3_dataset1_table2_set2, L3_dataset1_table3_set2]\n",
    "L3_dataset1_set2 = mergeDataSets(L3_dataset1_set2_list)\n",
    "# Merge L3 data from dataset2\n",
    "L3_dataset2_list = [L3_dataset2_table1_set1, L3_dataset2_table1_set2, L3_dataset2_table1_set3]\n",
    "L3_dataset2 = mergeDataSets(L3_dataset2_list)\n",
    "# Merge L3 data from dataset3\n",
    "L3_dataset3_list = [L3_dataset3_table1, L3_dataset3_table2_set1, L3_dataset3_table2_set2,\n",
    "                   L3_dataset3_table2_set3]\n",
    "L3_dataset3 = mergeDataSets(L3_dataset3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge OPAL data from dataset1\n",
    "OPAL_dataset1_list = [OPAL_dataset1_table1, OPAL_dataset1_table2, OPAL_dataset1_table3,OPAL_dataset1_table4]\n",
    "OPAL_dataset1 = mergeDataSets(OPAL_dataset1_list)\n",
    "# Merge OPAL data from dataset2\n",
    "OPAL_dataset2_list = [OPAL_dataset2_table1_set1, OPAL_dataset2_table1_set2, OPAL_dataset2_table1_set3,\n",
    "                      OPAL_dataset2_table2_set1, OPAL_dataset2_table2_set2, OPAL_dataset2_table2_set3,\n",
    "                      OPAL_dataset2_table3, OPAL_dataset2_table4_set1, OPAL_dataset2_table4_set2,\n",
    "                      OPAL_dataset2_table4_set3,OPAL_dataset2_table4_set4, OPAL_dataset2_table4_set5,\n",
    "                      OPAL_dataset2_table4_set6]\n",
    "OPAL_dataset2 = mergeDataSets(OPAL_dataset2_list)\n",
    "# Merge OPAL data from dataset3\n",
    "OPAL_dataset3_list = [OPAL_dataset3_table1, OPAL_dataset3_table2]\n",
    "OPAL_dataset3 = mergeDataSets(OPAL_dataset3_list)\n",
    "# Merge OPAL data from dataset4\n",
    "OPAL_dataset4_list = [OPAL_dataset4_table1, OPAL_dataset4_table2, OPAL_dataset4_table3,\n",
    "                     OPAL_dataset4_table4, OPAL_dataset4_table5, OPAL_dataset4_table6]\n",
    "OPAL_dataset4 = mergeDataSets(OPAL_dataset4_list)\n",
    "# Merge OPAL data from dataset5\n",
    "OPAL_dataset5_list = [OPAL_dataset5_table1, OPAL_dataset5_table3, OPAL_dataset5_table4,\n",
    "                     OPAL_dataset5_table5, OPAL_dataset5_table6, OPAL_dataset5_table7,\n",
    "                     OPAL_dataset5_table13]\n",
    "OPAL_dataset5 = mergeDataSets(OPAL_dataset5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALEPH data to use\n",
    "ALEPH_dataset2[ALEPH_dataset2[\"X\"] <= 0.01]\n",
    "# L3 dats to use\n",
    "L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235]\n",
    "# OPAL data to use\n",
    "OPAL_dataset3[OPAL_dataset3[\"X\"] <= 0.0235]\n",
    "OPAL_dataset4[OPAL_dataset4[\"X\"] <= 0.0235]\n",
    "# TPC data to use\n",
    "TPC_data[TPC_data[\"X\"] <= 0.0235]\n",
    "len(L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235]) + len(OPAL_dataset3[OPAL_dataset3[\"X\"] <= 0.0235]) + len(OPAL_dataset4[OPAL_dataset4[\"X\"] <= 0.0235]) + len(TPC_data[TPC_data[\"X\"] <= 0.0235])+len(ALEPH_dataset2[ALEPH_dataset2[\"X\"] <= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arturamorim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/arturamorim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# ALEPH data\n",
    "ALEPH_data = ALEPH_dataset2[ALEPH_dataset2[\"X\"] <= 0.01]\n",
    "ALEPH_data.columns = ['X', 'X LOW', 'X HIGH', 'Q**2 [GEV**2]', 'Q**2 [GEV**2] LOW',\n",
    "       'Q**2 [GEV**2] HIGH', 'F2/ALPHAE', 'stat +', 'stat -', 'sys +',\n",
    "       'sys -']\n",
    "ALEPH_data[\"error +\"] = np.sqrt(ALEPH_data[\"stat +\"]**2 + ALEPH_data[\"sys +\"]**2)\n",
    "ALEPH_data[\"error -\"] = np.sqrt(ALEPH_data[\"stat -\"]**2 + ALEPH_data[\"sys -\"]**2)\n",
    "ALEPH_data = ALEPH_data[[\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2/ALPHAE\", \"error +\", \"error -\"]]\n",
    "# OPAL data\n",
    "OPAL_data = mergeDataSets([OPAL_dataset3[OPAL_dataset3[\"X\"] <= 0.0235], OPAL_dataset4[OPAL_dataset4[\"X\"] <= 0.0235]])\n",
    "OPAL_data[\"error +\"] = np.sqrt(OPAL_data[\"stat +\"] ** 2 + OPAL_data[\"sys +\"] ** 2)\n",
    "OPAL_data[\"error -\"] = np.sqrt(OPAL_data[\"stat -\"] ** 2 + OPAL_data[\"sys -\"] ** 2)\n",
    "OPAL_data = OPAL_data[[\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\",\n",
    "                      \"F2/ALPHAE\", \"error +\", \"error -\"]]\n",
    "# TPC data\n",
    "TPC_data = TPC_data[TPC_data[\"X\"] <= 0.0235]\n",
    "TPC_data.columns = [\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\",\n",
    "                      \"F2/ALPHAE\", \"error +\", \"error -\"]\n",
    "# L3 data\n",
    "# Average the measurements of set1 and set2 of L3.\n",
    "# The differences are due to data unfolding\n",
    "f2 = 0.5 * (L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"F2(C=SET1)/ALPHA\"]+L3_dataset1_set2[L3_dataset1_set2[\"X\"] <= 0.0235][\"F2(C=SET2)/ALPHA\"])\n",
    "stat_plus = np.sqrt(0.5*(L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"stat +\"]**2+L3_dataset1_set2[L3_dataset1_set2[\"X\"] <= 0.0235][\"stat +\"]**2))\n",
    "stat_minus = np.sqrt(0.5*(L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"stat -\"]**2+L3_dataset1_set2[L3_dataset1_set2[\"X\"] <= 0.0235][\"stat -\"]**2))\n",
    "sys_plus = np.sqrt(0.5*(L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"sys +\"]**2+L3_dataset1_set2[L3_dataset1_set2[\"X\"] <= 0.0235][\"sys +\"]**2))\n",
    "sys_minus = np.sqrt(0.5*(L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"sys -\"]**2+L3_dataset1_set2[L3_dataset1_set2[\"X\"] <= 0.0235][\"sys -\"]**2))\n",
    "# Create the data frame of L3_data\n",
    "L3_data = pd.DataFrame({\"X\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"X\"],\n",
    "                       \"X LOW\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"X LOW\"],\n",
    "                       \"X HIGH\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"X HIGH\"],\n",
    "                       \"Q**2 [GEV**2]\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"Q**2 [GEV**2]\"],\n",
    "                       \"Q**2 [GEV**2] LOW\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"Q**2 [GEV**2] LOW\"],\n",
    "                       \"Q**2 [GEV**2] HIGH\": L3_dataset1_set1[L3_dataset1_set1[\"X\"] <= 0.0235][\"Q**2 [GEV**2] HIGH\"],\n",
    "                       \"F2/ALPHAE\": f2,\n",
    "                       \"stat +\": stat_plus,\n",
    "                       \"stat -\": stat_minus,\n",
    "                       \"sys +\": sys_plus,\n",
    "                       \"sys -\": sys_minus})\n",
    "L3_data[\"error +\"] = np.sqrt(L3_data[\"stat +\"]**2 + L3_data[\"sys +\"]**2)\n",
    "L3_data[\"error -\"] = np.sqrt(L3_data[\"stat -\"]**2 + L3_data[\"sys -\"]**2)\n",
    "L3_data = L3_data[[\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\", \"F2/ALPHAE\", \"error +\", \"error -\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything\n",
    "data_for_fit = mergeDataSets([ALEPH_data, OPAL_data, L3_data, TPC_data])\n",
    "data_for_fit[\"error -\"] = np.abs(data_for_fit[\"error -\"])\n",
    "data_for_fit[\"error\"] = np.maximum(data_for_fit[\"error +\"], data_for_fit[\"error -\"])\n",
    "data_for_fit = data_for_fit[[\"X\", \"X LOW\", \"X HIGH\", \"Q**2 [GEV**2]\", \"Q**2 [GEV**2] LOW\", \"Q**2 [GEV**2] HIGH\",\n",
    "                            \"F2/ALPHAE\", \"error\"]]\n",
    "# Save in txt file\n",
    "data_for_fit.to_csv(\"F2_photon_xmax_0.01.txt\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
